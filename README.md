# PIM
The articles related to PIM
## ReRAM
### Simulator
(TCAD 2012) [NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory](https://seal.ece.ucsb.edu/sites/default/files/publications/2012-NVsim-TCAD.pdf)

(DATE 2016) [MNSIM: Simulation platform for memristor-based neuromorphic computing system](https://seal.ece.ucsb.edu/sites/default/files/publications/07459356.pdf)

(TCAD 2018) [NeuroSim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning](https://asu.pure.elsevier.com/en/publications/neurosim-a-circuit-level-macro-model-for-benchmarking-neuro-inspi)

### Paper
(ISCA 2016) [ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7551379)

(ISCA 2016) [PRIME: A Novel Processing-in-Memory Architecture for Neural Network Computation in ReRAM-Based Main Memory](https://seal.ece.ucsb.edu/sites/default/files/publications/prime_isca_2016.pdf)

(HPCA 2017) [PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7920854)

(DAC 2018) [SNrram: An Efficient Sparse Neural Network Computation Architecture Based on Resistive Random-Access Memory](https://seal.ece.ucsb.edu/sites/default/files/publications/a106-wang_0.pdf)

(ICCAD 2018) [DL-RSIM: A simulation framework to enable reliable ReRAM-based accelerators for deep learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8587661)

(ASPDAC 2019) [Learning the sparsity for ReRAM: mapping and pruning sparse neural network for ReRAM based accelerator](https://seal.ece.ucsb.edu/sites/default/files/publications/p639-lin.pdf)

(ASPDAC 2019) [CompRRAE: RRAM-based convolutional neural network accelerator with reduced computations through a runtime activation estimation](https://dl.acm.org/doi/10.1145/3287624.3287640)

(VLSI 2019) [SubMac: Exploiting the subword-based computation in RRAM-based CNN accelerator for energy saving and speedup](https://www.sciencedirect.com/science/article/pii/S0167926019301786)

(Yiran Chen'2019) [ReBNN: in-situ acceleration of binarized neural networks in ReRAM using complementary resistive cell](https://link.springer.com/content/pdf/10.1007/s42514-019-00014-8.pdf)

(ISCA 2019) [Sparse ReRAM engine: joint exploration of activation and weight sparsity in compressed neural networks](https://dl.acm.org/doi/pdf/10.1145/3307650.3322271)

(TCAD 2020) [SemiMap: A Semi-Folded Convolution Mapping for Speed-Overhead Balance on Crossbars](https://seal.ece.ucsb.edu/sites/default/files/publications/tcad-2019-lei.pdf)

(Nature 2020) [Fully hardware-implemented memristor convolutional neural network](https://www.nature.com/articles/s41586-020-1942-4.pdf)

(ISCA 2020) [GaaS-X: Graph Analytics Accelerator Supporting Sparse Data Representation using Crossbar Architectures](https://conferences.computer.org/isca/pdfs/ISCA2020-4QlDegUf3fKiwUXfV0KdCm/466100a433/466100a433.pdf)

(TCAD 2020) [Long Live TIME: Improving Lifetime and Security for NVM-Based Training-in-Memory Systems](https://nicsefc.ee.tsinghua.edu.cn/media/publications/2020/IEEE%20TCAD_302_yrurbfj.pdf)

## SRAM
(ISCA 2018) [Neural Cache: Bit-Serial In-Cache Acceleration of Deep Neural Networks](https://dl.acm.org/doi/pdf/10.1109/ISCA.2018.00040)

(HPCA 2019) [Bit Prudent In-Cache Acceleration of Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/document/8675204)
*** 
# QuantPaper
The articles related to quantization
## Basic Network
(AlexNet) [ImageNet Classification with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf) 

(VGG) [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) / [homepage](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)

(GoogLeNet) [Going deeper with convolutions](https://arxiv.org/pdf/1409.4842.pdf)

(ResNet) [Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385) / [slides](http://kaiminghe.com/cvpr16resnet/cvpr2016_deep_residual_learning_kaiminghe.pdf)

(ShuffleNet) [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices](https://arxiv.org/abs/1707.01083)

(MobileNet V1) [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf) 

(MobileNet V2) [MobileNetV2: Inverted Residuals and Linear Bottlenecks](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf)


## CVF [Computer Vision Foundation open access](http://openaccess.thecvf.com/menu.py)

(ICCV 2019) [HAWQ: Hessian AWare Quantization of Neural Networks With Mixed-Precision](http://openaccess.thecvf.com/content_ICCV_2019/papers/Dong_HAWQ_Hessian_AWare_Quantization_of_Neural_Networks_With_Mixed-Precision_ICCV_2019_paper.pdf) 

(ICCV 2019) [Unsupervised Neural Quantization for Compressed-Domain Similarity Search](http://openaccess.thecvf.com/content_ICCV_2019/papers/Morozov_Unsupervised_Neural_Quantization_for_Compressed-Domain_Similarity_Search_ICCV_2019_paper.pdf)

(ICCV 2019) [Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks](http://openaccess.thecvf.com/content_ICCV_2019/papers/Gong_Differentiable_Soft_Quantization_Bridging_Full-Precision_and_Low-Bit_Neural_Networks_ICCV_2019_paper.pdf)

(ICCV 2019) [Learning Filter Basis for Convolutional Neural Network Compression](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Learning_Filter_Basis_for_Convolutional_Neural_Network_Compression_ICCV_2019_paper.pdf)

(ICCV 2019) [Learning Filter Basis for Convolutional Neural Network Compression](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Learning_Filter_Basis_for_Convolutional_Neural_Network_Compression_ICCV_2019_paper.pdf)

(CVPR 2019) [Quantization Networks](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Quantization_Networks_CVPR_2019_paper.pdf)


(CVPR 2019) [Fully Quantized Network for Object Detection](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Fully_Quantized_Network_for_Object_Detection_CVPR_2019_paper.pdf)


(CVPR 2019) [HAQ: Hardware-Aware Automated Quantization with Mixed Precision](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_HAQ_Hardware-Aware_Automated_Quantization_With_Mixed_Precision_CVPR_2019_paper.pdf) *Song Han* 


(CVPR 2019) [Simultaneously Optimizing Weight and Quantizer of Ternary Neural Networkusing Truncated Gaussian Approximation](http://openaccess.thecvf.com/content_CVPR_2019/papers/He_Simultaneously_Optimizing_Weight_and_Quantizer_of_Ternary_Neural_Network_Using_CVPR_2019_paper.pdf)


(CVPR 2019) [SeerNet: Predicting Convolutional Neural Network Feature-Map Sparsitythrough Low-Bit Quantization](http://openaccess.thecvf.com/content_CVPR_2019/papers/Cao_SeerNet_Predicting_Convolutional_Neural_Network_Feature-Map_Sparsity_Through_Low-Bit_Quantization_CVPR_2019_paper.pdf)

(CVPR 2018) [Quantization and Training of Neural Networks for EfficientInteger-Arithmetic-Only Inference](http://openaccess.thecvf.com/content_cvpr_2018/html/Jacob_Quantization_and_Training_CVPR_2018_paper.html)  *Google* 

(ECCV 2018) [Quantization Mimic: Towards Very Tiny CNNfor Object Detection](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yi_Wei_Quantization_Mimic_Towards_ECCV_2018_paper.pdf)

(ECCV 2018) [LQ-Nets: Learned Quantization for HighlyAccurate and Compact Deep Neural Networks](http://openaccess.thecvf.com/content_ECCV_2018/papers/Dongqing_Zhang_Optimized_Quantization_for_ECCV_2018_paper.pdf) 

(ECCV 2018) [Value-aware Quantizationfor Training and Inference of Neural Networks](http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunhyeok_Park_Value-aware_Quantization_for_ECCV_2018_paper.pdf)

NIPS, ICLR, etc. [LINK](https://openreview.net/)

## [ICLR 2019](https://openreview.net/group?id=ICLR.cc/2019/Conference)
(ICLR 2019) [Smart Ternary Quantization](https://openreview.net/pdf?id=SyxhaxBKPS)

(ICLR 2019) [Relaxed Quantization for Discretized Neural Networks](https://openreview.net/pdf?id=HkxjYoCqKX)

(ICLR 2019) [ProxQuant: Quantized Neural Networks via Proximal Operators](https://openreview.net/pdf?id=HyzMyhCcK7) 

(ICLR 2019) [Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets](https://openreview.net/pdf?id=Skh4jRcKQ)

(ICLR 2019) [From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference](https://openreview.net/pdf?id=Syxt2jC5FX)

(ICLR 2019) [Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm](https://openreview.net/pdf?id=rkxaNjA9Ym)

(ICLR 2019) [Analysis of Quantized Models](https://openreview.net/pdf?id=ryM_IoAqYX)

(ICLR 2019) [Defensive Quantization: When Efficiency Meets Robustness](https://openreview.net/pdf?id=ryetZ20ctX) *Song Han*

(ICLR 2018) [Mixed Precision Training of Convolutional Neural Networks using Integer Operations](https://openreview.net/pdf?id=H135uzZ0-)  *Intel* 

## [NIPS](http://papers.nips.cc/)

(NIPS 2019) [Focused Quantization for Sparse CNNs](http://papers.nips.cc/paper/8796-focused-quantization-for-sparse-cnns.pdf)

(NIPS 2019) [A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth Trade-Off](http://papers.nips.cc/paper/8926-a-mean-field-theory-of-quantized-deep-networks-the-quantization-depth-trade-off.pdf)

(NIPS 2019) [Post training 4-bit quantization of convolutional networks for rapid-deployment](http://papers.nips.cc/paper/9008-post-training-4-bit-quantization-of-convolutional-networks-for-rapid-deployment.pdf)

(NIPS 2019) [Generalization Error Analysis of Quantized Compressive Learning](http://papers.nips.cc/paper/9651-generalization-error-analysis-of-quantized-compressive-learning.pdf)

(NIPS 2019) [Latent Weights Do Not Exist: Rethinking Binarized Neural Network Optimization](http://papers.nips.cc/paper/8971-latent-weights-do-not-exist-rethinking-binarized-neural-network-optimization.pdf) 

(NIPS 2019) [Double Quantization for Communication-Efficient Distributed Optimization](http://papers.nips.cc/paper/8694-double-quantization-for-communication-efficient-distributed-optimization.pdf)


## [ICML](http://proceedings.mlr.press/v97/)
(ICML 2019) [Improving Neural Network Quantization without Retraining using Outlier Channel Splitting](http://proceedings.mlr.press/v97/zhao19c/zhao19c.pdf)

## [AAAI](https://dblp.uni-trier.de/db/conf/aaai/aaai2019.html)
(AAAI 2019) [Multi‐Precision  Quantized  Neural  Networks  via  Encoding  Decomposition  of  {-1,+1}](https://aaai.org/ojs/index.php/AAAI/article/view/4434)

(AAAI 2019) [Efficient  Quantization  for  Compact  Neural  Networks  with  Binary  Weights  and  Low  Bitwidth  Activations](https://aaai.org/ojs/index.php/AAAI/article/view/4273)

(AAAI 2019) [Deep Neural Network Quantization via Layer-Wise Optimization Using Limited Training Data](https://aaai.org/ojs/index.php/AAAI/article/view/4206)

## [IJCAI](https://dblp.uni-trier.de/db/conf/ijcai/ijcai2019.html)
(IJCAI 2019) [KCNN: Kernel-wise Quantization to Remarkably Decrease Multiplications in Convolutional Neural Network](https://www.ijcai.org/proceedings/2019/128)

(IJCAI 2019) [Binarized Neural Networks for Resource-Efficient Hashing with Minimizing Quantization Loss](https://www.ijcai.org/proceedings/2019/145)

(IJCAI 2019) [ KCNN: Kernel-wise Quantization to Remarkably Decrease Multiplications in Convolutional Neural Network](https://www.ijcai.org/proceedings/2019/588)

